{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pylab import plot,subplot,axis,stem,show,figure\n",
    "\n",
    "def getcomponents(A):\n",
    " #Subtract the mean to the data matrix\n",
    " M =  (A - np.mean(A,axis=0)).T\n",
    "    \n",
    " #Compute Covariance Matrix\n",
    " COV = np.cov(M)\n",
    "    \n",
    "    \n",
    " #Eigendecomposition\n",
    " eigval, eigvec = np.linalg.eig(COV)\n",
    "    \n",
    " #Projection of the data in the new space\n",
    " projection = np.dot(eigvec.T,M)\n",
    "    \n",
    " print(eigval) \n",
    " return eigval,projection,eigvec\n",
    "\n",
    "#Define the matrix\n",
    "A = np.array([ [2.4,0.7,2.9,2.2,3.0,2.7,1.6,1.1,1.6,0.9],\n",
    "[2.5,0.5,2.2,1.9,3.1,2.3,2,1,1.5,1.1] ])\n",
    "eigval,projection,eigvec = getcomponents(A.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "figure()\n",
    "subplot(121)\n",
    "\n",
    "# every eigenvector describe the direction\n",
    "# of a principal component.\n",
    "m = np.mean(A,axis=1) \n",
    "plot([0, -eigvec[0,0]*2]+m[0], [0, -eigvec[0,1]*2]+m[1],'--k')\n",
    "plot([0, eigvec[1,0]*2]+m[0], [0, eigvec[1,1]*2]+m[1],'--k')\n",
    "plot(A[0,:],A[1,:],'ob') # the data\n",
    "axis('equal')\n",
    "subplot(122)\n",
    "\n",
    "# New data\n",
    "plot(projection[0,:],projection[1,:],'*g')\n",
    "axis('equal')\n",
    "show()\n",
    "\n",
    "perc =  (eigval)/sum(eigval)\n",
    "figure()\n",
    "\n",
    "# the following plot shows that first two components\n",
    "# account for 100% of the variance.\n",
    "stem(range(len(perc)),perc,'--b')\n",
    "axis([-0.3,4.3,0,1.3])\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_classification_2D(input_data, output_data, weights):\n",
    "    \"\"\" Allows to plot 2-dimensional data (format (1, x1, x2)) using matplotlib, as well as the hyperplane defined by the weights (b, w1, w2). \n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    # Analyse training data\n",
    "    xmin=min(input_data[:,1])\n",
    "    xmax=max(input_data[:,1])\n",
    "    ymin=min(input_data[:,2])\n",
    "    ymax=max(input_data[:,2])\n",
    "    \n",
    "    # Plot the data\n",
    "    positive_class=input_data[output_data>0]\n",
    "    negative_class=input_data[output_data<=0]\n",
    "    plt.plot(positive_class[:,1], positive_class[:,2], 'ro')\n",
    "    plt.plot(negative_class[:,1], negative_class[:,2], 'bo')\n",
    "    \n",
    "    # Plot the hyperplane \n",
    "    x=linspace(xmin-0.1, xmax+0.1, 2)\n",
    "    y=-weights[1]/weights[2] * x - weights[0]/weights[2]\n",
    "    plt.plot(x, y, 'g-')\n",
    "    plt.axis([xmin-0.1, xmax+0.1, ymin-0.1, ymax+0.1])\n",
    "    plt.show()\n",
    " \n",
    "def load_training_set(filename):\n",
    "    \"\"\" Reads an input file called filename, containing the training examples in rows, the first column being always 1.0, and the last column being the output value.\n",
    "    \"\"\"\n",
    "    input_data=[]\n",
    "    output_data=[]\n",
    "    with open(filename, 'r') as ifile:\n",
    "        for line in ifile:\n",
    "            values=line.split()\n",
    "            input_value= [float(values[i]) for i in range(len(values)-1)]\n",
    "            output_value= float(values[len(values)-1])\n",
    "            input_data.append([float(values[i]) for i in range(len(values)-1)])\n",
    "            output_data.append(float(values[len(values)-1]))\n",
    "    return array(input_data), array(output_data)\n",
    " \n",
    " \n",
    "def project(input_data, weights):\n",
    "    \"\"\" Computes the projection of the input vector on the hyperplane defined by weights.\n",
    "    \"\"\"\n",
    "    return sum(input_data*weights)\n",
    "        \n",
    "###########################################        \n",
    "## Start of the perceptron algorithm ######\n",
    "###########################################\n",
    "# Value of the learning rate eta.\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Retrieve the data set from the file.\n",
    "input_data, output_data = load_training_set('linear_classification.data')\n",
    "\n",
    "# Initialize the weight vector to zero\n",
    "weights = zeros(len(input_data[0])) \n",
    "\n",
    "# The initial number of errors made on the training set is equal to the number of examples in the training set.\n",
    "error_count=len(input_data)\n",
    "\n",
    "# Number of times the training set was used (called epoch). \n",
    "nb_epochs=0 \n",
    "\n",
    "# Until there is no more errors on the training set, apply the perceptron learning rule\n",
    "while error_count>0: \n",
    "    print '-' * 60\n",
    "    error_count = 0\n",
    "    # Apply the perceptron algorithm on the training set\n",
    "    for index, input_vector in enumerate(input_data):\n",
    "        desired_output=output_data[index]\n",
    "        projection = project(input_vector, weights)\n",
    "        result = 1.0 if projection > 0.0 else (-1.0 if projection< 0.0 else 0.0)\n",
    "        if desired_output * projection <= 0:\n",
    "            error_count += 1\n",
    "            weights += learning_rate * (desired_output - result) * input_vector\n",
    "        print 'input', input_vector, 'desired_output', desired_output, 'projection', projection, 'result', result, 'weights', weights\n",
    "    # Increment the number of epochs \n",
    "    nb_epochs+=1\n",
    "    \n",
    "# Indicate the number of epochs needed to successfully classify the data.\n",
    "print 'Learning successful after', nb_epochs, 'epochs'\n",
    "# Show the data and the hyperplane in a figure.\n",
    "plot_classification_2D(input_data, output_data, weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_classification_2D(input_data, output_data, weights):\n",
    "    \"\"\" Allows to plot 2-dimensional data (format (1, x1, x2)) using matplotlib, as well as the hyperplane defined by the weights (b, w1, w2). \n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    # Analyse training data\n",
    "    xmin=min(input_data[:,1])\n",
    "    xmax=max(input_data[:,1])\n",
    "    ymin=min(input_data[:,2])\n",
    "    ymax=max(input_data[:,2])\n",
    "    \n",
    "    # Plot the data\n",
    "    positive_class=input_data[output_data>0]\n",
    "    negative_class=input_data[output_data<=0]\n",
    "    plt.plot(positive_class[:,1], positive_class[:,2], 'ro')\n",
    "    plt.plot(negative_class[:,1], negative_class[:,2], 'bo')\n",
    "    \n",
    "    # Plot the hyperplane \n",
    "    x=linspace(xmin-0.1, xmax+0.1, 2)\n",
    "    y=-weights[1]/weights[2] * x - weights[0]/weights[2]\n",
    "    plt.plot(x, y, 'g-')\n",
    "    plt.axis([xmin-0.1, xmax+0.1, ymin-0.1, ymax+0.1])\n",
    "    plt.title('Learning rae of 0.9')\n",
    "    plt.show()\n",
    " \n",
    "def load_training_set(filename):\n",
    "    \"\"\" Reads an input file called filename, containing the training examples in rows, the first column being always 1.0, and the last column being the output value.\n",
    "    \"\"\"\n",
    "    input_data=[]\n",
    "    output_data=[]\n",
    "    with open(filename, 'r') as ifile:\n",
    "        for line in ifile:\n",
    "            values=line.split()\n",
    "            input_value= [float(values[i]) for i in range(len(values)-1)]\n",
    "            output_value= float(values[len(values)-1])\n",
    "            input_data.append([float(values[i]) for i in range(len(values)-1)])\n",
    "            output_data.append(float(values[len(values)-1]))\n",
    "    return array(input_data), array(output_data)\n",
    " \n",
    " \n",
    "def project(input_data, weights):\n",
    "    \"\"\" Computes the projection of the input vector on the hyperplane defined by weights.\n",
    "    \"\"\"\n",
    "    return sum(input_data*weights)\n",
    "        \n",
    "###########################################        \n",
    "## Start of the perceptron algorithm ######\n",
    "###########################################\n",
    "# Value of the learning rate eta.\n",
    "learning_rate = 0.9\n",
    "\n",
    "# Retrieve the data set from the file.\n",
    "input_data, output_data = load_training_set('linear_classification.data')\n",
    "\n",
    "# Initialize the weight vector to zero\n",
    "weights = ones(len(input_data[0])) \n",
    "\n",
    "# The initial number of errors made on the training set is equal to the number of examples in the training set.\n",
    "error_count=len(input_data)\n",
    "# Number of times the training set was used (called epoch). \n",
    "nb_epochs=0 \n",
    "\n",
    "# Until there is no more errors on the training set, apply the perceptron learning rule\n",
    "while error_count>0: \n",
    "    print '-' * 60\n",
    "    error_count = 0\n",
    "    # Apply the perceptron algorithm on the training set\n",
    "    for index, input_vector in enumerate(input_data):\n",
    "        desired_output=output_data[index]\n",
    "        projection = project(input_vector, weights)\n",
    "        result = 1.0 if projection > 0.0 else (-1.0 if projection< 0.0 else 0.0)\n",
    "        if desired_output * projection <= 0:\n",
    "            error_count += 1\n",
    "            weights += learning_rate * (desired_output - result) * input_vector\n",
    "        print 'input', input_vector, 'desired_output', desired_output, 'projection', projection, 'result', result, 'weights', weights\n",
    "    # Increment the number of epochs \n",
    "    nb_epochs+=1\n",
    "    \n",
    "# Indicate the number of epochs needed to successfully classify the data.\n",
    "print 'Learning successful after', nb_epochs, 'epochs'\n",
    "# Show the data and the hyperplane in a figure.\n",
    "plot_classification_2D(input_data, output_data, weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_classification_2D(input_data, output_data, weights):\n",
    "    \"\"\" Allows to plot 2-dimensional data (format (1, x1, x2)) using matplotlib, as well as the hyperplane defined by the weights (b, w1, w2). \n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    # Analyse training data\n",
    "    xmin=min(input_data[:,1])\n",
    "    xmax=max(input_data[:,1])\n",
    "    ymin=min(input_data[:,2])\n",
    "    ymax=max(input_data[:,2])\n",
    "    \n",
    "    # Plot the data\n",
    "    positive_class=input_data[output_data>0]\n",
    "    negative_class=input_data[output_data<=0]\n",
    "    plt.plot(positive_class[:,1], positive_class[:,2], 'ro')\n",
    "    plt.plot(negative_class[:,1], negative_class[:,2], 'bo')\n",
    "    \n",
    "    # Plot the hyperplane \n",
    "    x=linspace(xmin-0.1, xmax+0.1, 2)\n",
    "    y=-weights[1]/weights[2] * x - weights[0]/weights[2]\n",
    "    plt.plot(x, y, 'g-')\n",
    "    plt.axis([xmin-0.1, xmax+0.1, ymin-0.1, ymax+0.1])\n",
    "    plt.title('Learning rae of 0.9')\n",
    "    plt.show()\n",
    " \n",
    "def load_training_set(filename):\n",
    "    \"\"\" Reads an input file called filename, containing the training examples in rows, the first column being always 1.0, and the last column being the output value.\n",
    "    \"\"\"\n",
    "    input_data=[]\n",
    "    output_data=[]\n",
    "    with open(filename, 'r') as ifile:\n",
    "        for line in ifile:\n",
    "            values=line.split()\n",
    "            input_value= [float(values[i]) for i in range(len(values)-1)]\n",
    "            output_value= float(values[len(values)-1])\n",
    "            input_data.append([float(values[i]) for i in range(len(values)-1)])\n",
    "            output_data.append(float(values[len(values)-1]))\n",
    "    return array(input_data), array(output_data)\n",
    " \n",
    " \n",
    "def project(input_data, weights):\n",
    "    \"\"\" Computes the projection of the input vector on the hyperplane defined by weights.\n",
    "    \"\"\"\n",
    "    return sum(input_data*weights)\n",
    "        \n",
    "###########################################        \n",
    "## Start of the perceptron algorithm ######\n",
    "###########################################\n",
    "# Value of the learning rate eta.\n",
    "learning_rate = 0.9\n",
    "# Retrieve the data set from the file.\n",
    "input_data, output_data = load_training_set('xor.data')\n",
    "\n",
    "# Initialize the weight vector to zero\n",
    "weights = ones(len(input_data[0])) \n",
    "# The initial number of errors made on the training set is equal to the number of examples in the training set.\n",
    "error_count=len(input_data)\n",
    "# Number of times the training set was used (called epoch). \n",
    "nb_epochs=0 \n",
    "\n",
    "# Until there is no more errors on the training set, apply the perceptron learning rule\n",
    "while error_count>0: \n",
    "    print '-' * 60\n",
    "    error_count = 0\n",
    "    # Apply the perceptron algorithm on the training set\n",
    "    for index, input_vector in enumerate(input_data):\n",
    "        desired_output=output_data[index]\n",
    "        projection = project(input_vector, weights)\n",
    "        result = 1.0 if projection > 0.0 else (-1.0 if projection< 0.0 else 0.0)\n",
    "        if desired_output * projection <= 0:\n",
    "            error_count += 1\n",
    "            weights += learning_rate * (desired_output - result) * input_vector\n",
    "        print 'input', input_vector, 'desired_output', desired_output, 'projection', projection, 'result', result, 'weights', weights\n",
    "    # Increment the number of epochs \n",
    "    nb_epochs+=1\n",
    "    \n",
    "# Indicate the number of epochs needed to successfully classify the data.\n",
    "print 'Learning successful after', nb_epochs, 'epochs'\n",
    "# Show the data and the hyperplane in a figure.\n",
    "plot_classification_2D(input_data, output_data, weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "#Dataset\n",
    "X_train = np.array([[1.3,2.1,1.5,1.5,5.9,4.1,3.9],[2.1,2.9,2.7,2.5,3.1,3.9,4.1]])\n",
    "\n",
    "X_test = np.array([[2.3,3.2,1.3,3.5,6.9,2.1],[5.1,2.9,2.2,1.5,2.1,1.4]])\n",
    "\n",
    "y_train = [1,1,1,1,0,0,0]\n",
    "\n",
    "# Euclidean Distance\n",
    "def euclide_distance(data1,data2):\n",
    "    dist = [(data1[i]-data2[i])**2 for i in range(len(data1))]\n",
    "    sqrt_distance = np.sqrt(np.sum(dist))\n",
    "    return sqrt_distance\n",
    "\n",
    "# Vectorize the dataset\n",
    "datasets = X_train.T\n",
    "test = X_test.T\n",
    "#print(test)\n",
    "\n",
    "\n",
    "#test for k =3. The code can also be implemented on k=4\n",
    "k = 3\n",
    "def neighbour(train,test,k):\n",
    "    distance=  np.array([euclide_distance(data1,test) for data1 in train])\n",
    "    return distance\n",
    "\n",
    "#intialize and empty list to store a vector\n",
    "c = []\n",
    "for n in range(len(test)):\n",
    "    vector = neighbour(datasets,test[n],3)\n",
    "    c = (np.append(c,vector,axis=0))\n",
    "\n",
    "# row vectors vector that contains the respective euclidean distance\n",
    "distance = c.reshape(len(test),len(datasets))\n",
    "\n",
    "# To classify the dataset with respect to the euclidean distance for eack k smallest ot the greatest which returns the label\n",
    "x_label = np.argsort(distance)[:,:k]\n",
    "\n",
    "#  To store all the label in form of row vector \n",
    "flatlabel =x_label.flatten()\n",
    "\n",
    "# classification based on class\n",
    "kneighbour = np.array([y_train[i] for i in flatlabel])\n",
    "\n",
    "resshape_t = kneighbour.reshape(len(test),k)\n",
    "\n",
    "#Prediction\n",
    "prediction = list()\n",
    "for row in resshape_t :\n",
    "      result = Counter(row).most_common(1)[0][0] \n",
    "      prediction.append(result)\n",
    "print(prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pylab import plot,show\n",
    "from numpy import vstack,array\n",
    "from numpy.random import rand\n",
    "from scipy.cluster.vq import kmeans,vq\n",
    "\n",
    "\n",
    "# data generation\n",
    "data = vstack((rand(150,2) + array([.5,.5]),rand(150,2)))\n",
    "\n",
    "centroids,_ = kmeans(data,3)\n",
    "idx,_ = vq(data,centroids)\n",
    "\n",
    "plot(data[idx==0,0],data[idx==0,1],'ob',\n",
    "     data[idx==1,0],data[idx==1,1],'or',\n",
    "     data[idx==2,0],data[idx==2,1],'og') # third cluster points\n",
    "plot(centroids[:,0],centroids[:,1],'sm',markersize=8)\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import plot,show\n",
    "from numpy import vstack,array\n",
    "from numpy.random import rand\n",
    "from scipy.cluster.vq import kmeans,vq\n",
    "\n",
    "\n",
    "# data generation\n",
    "data = vstack((rand(150,2) + array([.5,.5]),rand(150,2)))\n",
    "\n",
    "centroids,_ = kmeans(data,4)\n",
    "idx,_ = vq(data,centroids)\n",
    "\n",
    "plot(data[idx==0,0],data[idx==0,1],'ob',\n",
    "     data[idx==1,0],data[idx==1,1],'or',\n",
    "     data[idx==2,0],data[idx==2,1],'og',\n",
    "     data[idx==2,1],data[idx==2,1],'oy') # forth cluster points\n",
    "plot(centroids[:,0],centroids[:,1],'sm',markersize=8)\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import plot,show\n",
    "from numpy import vstack,array,uint8,shape\n",
    "from numpy.random import rand\n",
    "from scipy.cluster.vq import kmeans,vq\n",
    "from PIL import Image\n",
    "\n",
    "# data generation\n",
    "#Load image\n",
    "im = Image.open(\"brainslice.jpg\")\n",
    "im_data =  array(im.getdata())\n",
    "r,c= shape(im)\n",
    "\n",
    "\n",
    "\n",
    "centroids,_ = kmeans(im_data,4).astype(float)\n",
    "idx,_ = vq(im_data,centroids).astype(float)\n",
    "\n",
    "class_Y = idx.reshape(r,c)*80\n",
    "\n",
    "im_final = Image.fromarray(uint8(class_Y))\n",
    "im_final = im_final.convert('RGB')\n",
    "im_final.save(\"class_im.jpg\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
